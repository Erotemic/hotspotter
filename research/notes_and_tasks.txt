qcx=GZ_305
qcx=GZ_111
first 4 are false matches
Reasons for failure:
* small (nondistinctive) keypoints match. 
Places where this occurs:
face - 
ridge of back
front chevron,



These descriptors tend to have one black bar running through the middle 
_____________
|    |||    |
|    |||    |
|    |||    |
|    |||    |
-----|||-----

dynamic scoring


changes: 
* dump images of individual matching keypoints. 
* the ones that scored really high. 

Contribution: 
* an open source system for instance recognition
* comparison to tf-idf bag-of-words
* comparison of descriptor types
* I am going to talk about these issues and how to solve them. 



PICK APPART GZ_111 vs GZ_305


Questions: 

I'm not sure that I'm plotting the keypoints correctly.

From the perdoch detector I get this: 

x, y - keypoint location
a, c, d - Lower triangular matrix A = [(a, 0),
                                       (c, d)]




1) You have animls you haven't seen before
2) Occlusions and viewpoint variations -> therefore you need multiple images
per animsl. 


Problem: Online recognition
Thousands of animals per day
Animals you haven't seen before 
Too many for manual verfication of everything 

Challenges / Contributions
1) Pose and viewpoint variations
2) Occlusions 
3) Similar appearances 
4) Incomplete views
5) Imperfect segmentation 


Proposed Contribution: 
1) Basic scoring mechanism (LNBNN vs TfIDF)
2) Decision involving multiple images per animal
- Driving appart true and false positives 
3) Dynamic database construction 
4) Construction of represntation of each animal including what to keep. 
(but not limited to)

We are in good shape on Scoring mechanism

we have some evidence that multi-iomage is correct but no mechanism. 
We have unclear results from our last paper
but the mechanism still needs to be investigated 

We have ideas on representation 


We dont understand the causes of failures


We dont have appropriate datasets
( * We want close to 1000 animals
  * 20 per animal at least (more is possible)
) 


Tasks:
Do my experiment  (ranked scores)
Organize datasets (with a script)

(mon and tues) Inventory and Aquisition 

(rest of the week) Detailed idea generation for all of our contributions
and evaluation. 



1) Online database where images are coming in sequentially 
 + we have a dynamic data structure 



-----------

In the external: 

3 Folders

+ OPC zebra Pic: (think this is the same as pdb)
|    Contains 5,341 images of plains zebras. (some grevy's)
|    some are corrupted. 
|    The naming scheme does not indicate any ground truth. 
|    There is a RESOURCE.FRK folder in here with what looks like  498 corrupted tif
|    images. Maybe its just metadata though. 
+ Sweetwaters pdb
L_+ Sweetwaters(8_03).fdb (54.2 MB)
|    (unsure what is in this)
L_+ Sweetwaters Portfolio Pics folder with 5,343 images
| L__ Also hae RESOURCE.FRK
|  
+ Zebra pics for testing
|  (123 Images. Mostly Plains + Some Grevy's. No ROI. 
    No GT, Mostly Centered. Good variation.)



Wildebeast: 
Lots of images. (over 1000) maybe we have ground truth. I haven't parsed it
yet. 

-----------------------------
Contribution Idea: 

Problem: When is a keypoint match actually a the same keypoint? 

Proposed solution: 
1) Find a keypoint's best $k$ matches. 
2) Increase / Decrease the scale of the keypoint in the warped affine frame. 
For both the query keypoints and its results. 

Observation: Sift is a histogram. Histogram intersection distance is probably 
more appropriate when the resources are available. 

The distance between scales at matching keypoints should be CONSISTENT. 
-----------------------------

Observation: small keypoints are can cause disproportinatelly high scores. 
(Example: cx=126 (02.135.jpg) PZ_DanExt_All
python extract_patch.py PZ_DanExt_All --qcx 126
(Lol, these are just numbers)

Observation: Big keypoints lose too many details and are not reliable: 
(Example: cx=1293 (09_321.jpg) PZ_DanExt_All
python extract_patch.py PZ_DanExt_All --qcx 1293



----

What if I don't hit the CVPR deadline. 

I feel like I'm shooting in the dark, and every time I think I hit something I
get discouraging feedback. 

I end up just rehashing the same old things over and over. 

The plus side is that a lot of those things were misses, and I gained a better
understanding of things through the rehashing. 

I don't want to feel under presure. 

I want to feel like I'm moving forward towards something good. 

I don't want to publish or do work for the sake of publishing or doing work. 

I'd like to find a difficult challenge and really work on it and continuously
make headway. 

I have a nice framework in which to run experiments. I'm very happy with this
version of HotSpotter. 

Looking at image level matches is no the correct approach. The features are
the fundamental unit which are doing the work. Those are what we should be
paying attention to. We should understand and improve upon their behavior.















------

Looking at: 

python extract_patch.py --qcx 182 LF_ALL --low 3 --high 13

The Finns match, but they don't get a decent normalizer. 

This is because the lines are consistent, but the placement of the dots can
vary so wildly. 

The lines make the fin keypoint sit close in descriptor space, but because the 
placement of the circles seems to vary, there will be significant distance
between the kth match and the normalizer. 


python extract_patch.py --qcx 182 LF_ALL --low 3 --high 13

python extract_patch.py --qcx 197 LF_ALL --low 0 --high 10

python extract_patch.py --qcx 369 LF_ALL --low 0 --high 10

python extract_patch.py --qcx 207 LF_ALL --low 0 --high 10

python extract_patch.py --qcx 700 LF_ALL --low 0 --high 10

python extract_patch.py --qcx 619 LF_ALL --low 0 --high 10

python extract_patch.py --qcx 169 LF_ALL --low 0 --high 10

python extract_patch.py --qcx 641 LF_ALL --low 0 --high 10

python extract_patch.py --qcx 48 LF_ALL --low 0 --high  10 --nodesc

python extract_patch.py --qcx 250 LF_ALL --low 0 --high 10 --nodesc

Failure Cases: 
Non rigid matches (lionfish fins) (deformable / independently moving parts) 
Viewpoint 
Occlusion 
Image Quality 
Background matches / partial background matches. 
Partial background matches / random configuration of animals. 
-
Compounded by textured regions with lots of matches
(there is a disproportionate scoring for regions which generate more
keypoints)




* Run With GTed wildebeast
* Upload nonmatching photos for ASIFT comparison
* Enumerate what other people have done in hotspotter2.tex
